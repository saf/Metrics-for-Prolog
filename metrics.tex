\documentclass[11pt,a4paper,twoside]{article}
\usepackage{a4wide}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{listings}
\usepackage{multicol}

\RequirePackage{times}
\RequirePackage{a4wide}
\RequirePackage{longtable}
\RequirePackage{multicol}
\RequirePackage{url}

\newcommand{\pname}{\emph{MFPL}}

\author{SÅ‚awomir Rudnicki}
\title{Adapting code metrics to Prolog}
\date{}

\begin{document}
\maketitle
\begin{abstract}
Blah blah blah
\end{abstract}
\begin{multicols}{2}


\section{Introduction}

\section{The Prolog language}

Prolog is a declarative programming language, whose syntax is based on
first-order logic. Since its creation around the year 1972, it has
found multiple applications in the fields of artificial intelligence
and natural language processing.

Prolog programs consist of definitions of \emph{relations} on
\emph{terms}. Intuitively, a run of the program seeks to determine
whether a relation holds for the given arguments, or to find a set of
arguments such that a given relation holds. In this document, I will
briefly describe the basics of logic programming to the extent that is
needed to understand the problems of adapting code metrics to it. A
thorough introduction to the core syntax and semantics of Prolog
itself can be found in the classic book by Clocksin and Mellish
\cite{clocksin}.



\section{Local complexity measure}


\section{Halstead's metrics}

Halstead \cite{halstead} proposed metrics for analysing the effort one
needs to make to code a program and then maintain it. The metrics are
largely based on psychological research of how one understands a
program by making ``mental comparisons'' of tokens.

Halstead's metrics are defined using two groups of source code tokens:
\emph{operators} and \emph{operands}. Let us denote:
\begin{itemize}
\item $N_1$ -- the number of all operators, 
\item $N_2$ -- the number of all operands, 
\item $n_1$ -- the number of distinct operators, 
\item $n_2$ -- the number of distinct operands.
\end{itemize}

The following metrics are then derived from those counts:
\begin{description}
\item[Program length]
  $$N = N_1 + N_2,$$ denotes the total length of the program, measured
  as the number of all tokens.
\item[Vocabulary]
  $$n = n_1 + n_2,$$ denotes the size of the program's vocabulary,
  i.e.  the number of distinct tokens that one has to consider to
  fully understand the program.
\item[Volume]
  $$V = N \cdot \log_2n,$$ which measures the size of the program when
  coded in binary form. The metric is based on the fact that every
  token of the analysed program can be coded with $log_2n$ bits.
\item[Difficulty]
  $$D = \frac{n_1}{2}\cdot\frac{N_2}{n_2},$$ measures how difficult
  the program is to create and maintain. According to Halstead, code
  is more sophisticated and error-prone if distinct operands occur
  many times in it..
\item[Level]
  $$L = \frac{1}{D}.$$ The inverse of difficulty, this metric may
  indicate whether a given program is written on a high- or
  low-level. For example, assembler code will tend to have a lower
  level value than Java code.
\item[Effort]
  $$E = V \cdot D.$$ The effort needed to write or understand a
  program is proportional to its size and difficulty.
\end{description}

Halstead moves on to propose experimentally derived, higher-level
metrics of code, including:
\begin{description}
\item[Time]
$$T = E/18,$$ which is the time needed to ``mentally'' implement the
  program, in seconds.
\item[Bugs]
$$B = E^{\frac{2}{3}}/3000,$$ which is the number of bugs that are
  delivered, on average, inside the program.
\end{description}

\subsection{Operators and operands}
The main problem with Halstead's metrics, however, is the definition
of what is an operator and what is an operand. For popular languages,
those notions have been thoroughly discussed. Nandy \cite{nandy} sums
up what seems to be the most common understanding of what operators
and operands are in C, C++ and Java. 

In declarative programming, it is not obvious how to discern operators
from operands. All language constructs of Prolog are in fact terms of
the form:
$$T(x_1, x_2, \dots, x_k).$$ 
Here, the number $k$ is the \emph{arity}
of the predicate symbol $T$, and $x_1, \dots, x_k$ are its
\emph{arguments}. We usually write $T/k$ to denote a term and its arity. 

When we thus write:
$$A\,\, is\,\, B + 1,$$ 
Prolog understands it as nothing but:
$$is(A, +(B, 1)).$$ When one takes into account the fact that function
names in Java function calls are commonly considered to be operands,
it is therefore tempting to view all terms as operands.

To add to this, Prolog is often used to write meta-programs --
programs that operate on Prolog source code. Some programs may even
manipulate parts of themselves during normal operation, further
blurring the notions of operators and operands. Of course,
\pname\ itself is an example of a meta-program.

In \pname, I have chosen a simple way of dividing tokens into operands
and operators. In a few words, it can be described as \emph{If it looks
  like an operator, it is an operator}. Operators are therefore all
symbols that may be used without the parenthetical notation $T(x, y)$
and may be instead written as: 
\begin{itemize}
\item $T\, x\, y$ (prefix notation),
\item $x\,T\, y$ (infix notation), or 
\item $x\, y\, T$ (postfix or reverse Polish notation).
\end{itemize}
All other relational symbols will be viewed as operands, even if they
are never an argument for another symbol.

The above decision is one that seems to be most in line with the
psychological basis of Halstead's metrics. When reading a Prolog
program, or any other code, we naturally consider tokens that take
advantage of the infix notation as operators, because this is what we
are used to from studying mathematics. Hovewer informal, this
observation would certainly be more important from Halstead's point of
view than the actual internal representation of terms.

We will therefore consider all built-in Prolog operators to be
operators in terms of Halstead's metrics. The built-in operators are,
for example:
\begin{itemize}
\item the rule-building predicate :-$/2$,
\item the conjunction and disjunction operators $,/2$ and $;/2$,
\item arithmetic operators, including $is/2$, $+/2$, $*/2$, 
\item arithmetic relations, such as $=</2$, 
\item bitwise and logical operators, including the logical alternative
  operator $\//2$ and the bitwise shift operator $<</2$.
\end{itemize}

ISO-Prolog contains a mechanism that allows the user to define their
own operators using the built-in predicate $op/3$. By writing: 
\begin{center}
\texttt{op(400, fx, '***')},
\end{center}
 we can allow the symbol \texttt{***}$/1$ to be used in prefix
notation. \pname's Halstead metrics will treat all such tokens as
operators.

There are also a few purely syntactical tokens that will also be
treated as operators:
\begin{itemize}
\item the pair of parentheses $()$ surrounding a symbol's arguments
  will be viewed as a single operator,
\item the dot that stands after every Prolog term will be viewed as a
  single operator, by analogy to C's semi-colon,
\item the list notation \texttt{[H | T]} will be treated as one
  operator.
\end{itemize}

\subsection{Variable distinctiveness}



\end{multicols}

\newpage

\begin{thebibliography}{halstead}
\bibitem{clocksin}
  W.F. Clocksin, C.S. Mellish, 
  \emph{Programming in Prolog}, 
  Springer-Verlag Telos, 1994.
\bibitem{halstead}
  M.H. Halstead, 
  \emph{Elements of Software Science}, 
  Elsevier, North-Holland, New York, 1977.
\bibitem{nandy}
  I. Nandy, 
  \emph{Halstead's Operators and Operands}
  Scribd.com, 2007.
\end{thebibliography}
\end{document}
